\---
layout: default
title: Singer Identification
\---
.page-header.title
  .row
    .span12
      %h1 Teaching Computers to Identify Singers
      %h1
        %small A Study in Signal Processing and Machine Learning
    .span4
      %p
        Northwestern University
        %br/
        EECS 349
        %br/
        Prof. Bryan Pardo

%section#team
  %h2 The Team
  .row
    .span4
      .team-member
        %address
          %img{:src=>"img/KaiSmall.jpg"}
          %a.name{:href=>"http://www.linkedin.com/pub/kai-hayashi/23/734/160"} Kai Hayashi
          %a{:mailto => ""} k.hermitian@gmail.com
    .span4
      .team-member
        %img{:src=>"img/cary_square.jpg"}
        %address
          %a.name{:href=>"http://www.caryme.com"} Cary Lee
          %br/
          %a{:mailto => ""} carylee@gmail.com
    .span4
      .team-member
        %img{:src=>"img/DanHornSmall.jpg"}
        %address
          %a.name{:href=>"http://linuxhaxor.blogspot.com/"} Daniel Myers
          %br/
          %a{:mailto => ""} dmritard96@gmail.com
    .span4
      .team-member
        %img{:src=>"img/BeckyPretty.jpg"}
        %address
          %a.name{:href=>"http://www.linkedin.com/pub/rebecca-nevin/28/932/2b8"} Rebecca Nevin
          %br/
          %a{:mailto => ""} rlnevin@gmail.com
.row
  .span16
    %section#background
      %h2 Background
      %p
        Identifying and differentiating the voices of individual singers is a
        task that comes naturally to humans. Consider the following recordings
        of two singers:
      .row
        .span-one-third
          %h3 Singer 1
          %audio{:controls=>"controls"}
            %source{:src=>"audio/mezzo2-excerpt.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
        .span-one-third
          %h3 Singer 2
          %audio{:controls=>"controls"}
            %source{:src=>"audio/tenor1-excerpt.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
      %br/
      %p
        Clearly, Singer 1 and Singer 2 are not the same person. Even after
        hearing only a short excerpt of each singer, we can distinguish between
        the two. We can deduce information about the singers, like their sexes or
        perhaps even their voice types. The task is somewhat more challenging with
        shorter samples given out of context, like the three below.
      .row
        .span-one-third
          %h3 Mystery Singer 1
          %audio{:controls=>"controls"}
            %source{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/samples/Mezzo1/mid/a/a2.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
          %a{:href=>"#background", 'data-placement'=>"below", :rel=>"twipsy", :title=>"Wildcard - not one of the singers above"} Who is it?
        .span-one-third
          %h3 Mystery Singer 2
          %audio{:controls=>"controls"}
            %source{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/samples/tenor1/high/a/a3.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
          %a{:href=>"#background", 'data-placement'=>"below", :rel=>"twipsy", :title=>"Singer 2"} Who is it?
        .span-one-third
          %h3 Mystery Singer 3
          %audio{:controls=>"controls"}
            %source{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/samples/mezzo2/mid/a/a2.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
          %a{:href=>"#background", 'data-placement'=>"below", :rel=>"twipsy", :title=>"Singer 1"} Who is it?

      %br/
      %p
        Even out of context, humans can usually differentiate between different
        singers' voices by the timbre, or quality, of the voice.  One of the
        most important components of what a human listener perceives as timbre
        is the spectral envelope of the singer's voice. The peaks of that to
        identify a singer is particularly useful because, as
        %a{:href=>"http://www.lma.cnrs-mrs.fr/~kronland/Sense_of_Sound/49690159.pdf"} Khine, Nwe, and Li
        explain, "studies suggest that timbre is invariant with an individual
        singer."

      %p
        This project explores the application of machine learning to develop an automated singer identifier, largely following
        the methodology of
        %a{:href=>"http://home.earthlink.net/~bartscma/caruso.pdf"} Wakefield and Bartsch.
        There many applications for this kind of automated singer identification, including:
      %ul
        %li Source differentiation in audio recordings
        %li Identification of a singers presence on an unlabeled track.

      %p
        One of the problems in trying to develop such a classifier is the question of how to quantify
        the timbral features of an audio recording for training and classification. In this project, we compare
        the performacne of compositie transfer functions (CTFs) as proposed by
        %a{:href=>"http://home.earthlink.net/~bartscma/caruso.pdf"} Wakefield and Bartsch
        and Mel frequency cepstral coefficients, as used by
        %a{:href=>"http://ismir2000.ismir.net/papers/logan_abs.pdf"} Logan.

    %section#dataset
      %h2 Data Set
      %p
        We recruited volunteer singers to be recorded and included as part of our
        data set.  We recorded a total of 11 classically trained singers from
        Northwestern University Bienen School of Music consisting of 3 sopranos,
        4 mezzo-sopranos, 2 tenors and 2 baritones.
      %p
        Each singer was asked to sing:
      %ul
        %li The first 5 notes of a major scale.
        %li Repeated in the low, middle and high regions of the singer’s range.
        %li Repeated for each of the 5 common Italian language vowels [a], [e], [i], [o], and [u]

      %p A single scale sounded like this (recorded at 44.1KHz, 16 bits/sample):
      %audio{:controls=>"controls"}
        %source{:src=>"audio/tenor2-a.wav", :type=>"audio/wav"}
        Your browser does not support the audio tag.

      %p
        These scales were then manually split into single-pitch, 1-second samples, totalling 825 samples (75 per singer).
      %a{:href=>"https://github.com/downloads/crxpandion/Singer_ID/samples.zip", :class=>"btn primary"} Download our data set (66MB)

    %section#signalprocessing
      %h2 Signal Processing
      %p Before machine learning can occur, the necessary features must be extracted from the raw audio files.
      %ol
        %li The Matlab Signal Processing toolbox was used to calculate a spectrogram for each signal.
        %li
          The formant was calculated using either an approximation of the CTF or code from
          %a{:href=>"http://labrosa.ee.columbia.edu/matlab/rastamat/"} Ellis 
          for generating MFCCs.
        %li Principle component analysis was performed on the outputs to generate data readable by
        %a{:href=>"http://www.csie.ntu.edu.tw/~cjlin/libsvm/"} LibSVM.
      .media-grid
        %a{:href=>"img/bd.png"}
          %img{:src=>"img/bd.png"}

    %section#learningmethod
      %h2 Learning Method
      %ul
        %li
          The
          %a{:href=>"http://www.cs.waikato.ac.nz/ml/weka/index.html"} WEKA software package
          was used to perform learning tasks.
        %li
          %a{:href=>"http://www.csie.ntu.edu.tw/~cjlin/libsvm/"} LibSVM
          was used with quadratic classifiers.
        %li Ten-fold cross-validation.
        %li
          Samples were classified on three different levels:
          %ol
            %li Individual singers
            %li Voice Type
            %li Sex
        %li Performance was measured as the percentage of correctly classified samples.

    %section#results
      %h2 Results
      %h3 Composite Transfer Functions vs. Mel Frequency Cepstral Coefficients
      %ul.media-grid.confusion
        %li
          %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Formant_all_Confusion.png", 'data-placement'=>"below", :rel=>"twipsy", :title=>"Confusion matrix for individual singers using CTF"}
            %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Formant_all_Confusion.png"}
        %li
          %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_all_Confusion.png", 'data-placement'=>"below", :rel=>"twipsy", :title=>"Confusion matrix for individual singers using MFCC"}
            %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_all_Confusion.png"}
      %p
        The plots above show confusion matrices for the CTF approximation
        method (left) and the MFCC method (right). It is clear that MFCCs
        were more successful at classifying our samples.
      %h3 Classification Levels
      .row.boxplots
        .span5
          %p
            The box plots shown right summarize our learner’s ability to
            classify data samples at one of three levels: 
            %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerClassBox.png"} individuals
            (top left),
            %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerTypeClassBox.png"} voice type
            (top right), and
            %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SexClassBox.png"} sex
            (bottom left). As the classification
            becomes more general, the machine is more successful. There are
            several interesting conclusions to be drawn:
          %ul
            %li Very good at identifying sex
            %li Voice type and individual identification are more challenging
          %p
            Further investigation revealed that the
            %strong majority of voice type and individual errors occurred amongst the female samples,
            as can be seen in the 
            %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_all_Confusion.png"} individual confusion matrix 
            and the
            %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_Type_Confusion.png"} voice type confusion matrix
            (bottom right). The reasons for this are of
            great interest to us.
        .span11
          %ul.media-grid
            %li
              %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerClassBox.png", 'data-placement'=>"left", :rel=>"twipsy", :title=>"Classifying Individual Singers"}
                %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerClassBox.png"}
            %li
              %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerTypeClassBox.png", 'data-placement'=>"left", :rel=>"twipsy", :title=>"Classifying Voice Type"}
                %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SingerTypeClassBox.png"}
            %li
              %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SexClassBox.png", 'data-placement'=>"left", :rel=>"twipsy", :title=>"Classifying Sex"}
                %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/boxplots/SexClassBox.png"}
            %li
              %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_Type_Confusion.png", 'data-placement'=>"left", :rel=>"twipsy", :title=>"Classifying Voice Type"}
                %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/Confusion/Cepstral_Type_Confusion.png"}


    %section#discussion
      %h2 Discussion
      %h3 Sparse spectra:
      %p
        As
        %a{:href=>"http://home.earthlink.net/~bartscma/caruso.pdf"} Wakefield and Bartsch
        explain, the female voice typically has a higher
        fundamental frequency, such that the spectral envelopes generated by the female
        singers are sparser than those of the male singers. These sparse spectra
        likely contribute to our difficulty in classifying female voices. The plot
        below shows the CTF of the two audio samples given for a soprano and a
        mezzo-soprano and demonstrates how the similarities could cause
        confusion.

      .row
        .span7
          %h4 Soprano1
          %audio{:controls=>"controls"}
            %source{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/samples/Soprano1/mid/a/a2.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
          %h4 Mezzo1
          %audio{:controls=>"controls"}
            %source{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/samples/Mezzo1/mid/a/a1.wav", :type=>"audio/wav"}
            Your browser does not support the audio tag.
        .span9.media-grid
          %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/CTF/comparisionMezzo1Soprano1CTF.png", 'data-placement'=>"left", :rel=>"twipsy", :title=>"Classifying Individual Singers"}
            %img{:src=>"https://github.com/crxpandion/Singer_ID/raw/master/figures/CTF/comparisionMezzo1Soprano1CTF.png"}
      %h3 Voice maturity
      %p
        The age and maturity of our sample set must also be considered in evaluating
        the results. A young woman’s voice can continue to change and develop into her
        30’s. As such, it is not uncommon for young female singers to change voice
        types early in their career. Our vocalists are all under the age of 30 and our
        youngest singer, Mezzo3, is currently considering transitioning to soprano
        repertoire. Thus our results are more vulnerable to voice type discrepancies
        than a sample set of fully developed vocalists.
      %h3 Future research opportunities:
      %ol
        %li Could machines trained on matured singers help voice teachers identify the voice type of young students, particularly pre-mature females?
        %li How will a learner perform when the sample set contains more specific fachs such as coloratura soprano, lyric soprano, spinto soprano, and soubrette?
      .actions
        %a{:href=>"https://github.com/crxpandion/Singer_ID/raw/master/paper.pdf", :class=>"btn primary"} Read the paper
        %a{:href=>"https://github.com/crxpandion/Singer_ID", :class=>"btn"} View the source code
